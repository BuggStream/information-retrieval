{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PyTerrier\n",
    "\n",
    "_DSAIT4050: Information retrieval lecture, TU Delft_\n",
    "\n",
    "**Part 4: Evaluation & experiments**\n",
    "\n",
    "This part focuses on running experiments and evaluating retrieval and ranking models using PyTerrier. We'll learn how to use query relevances (QRels) to compute ranking metrics and perform statistical significance testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    },
    "ExecuteTime": {
     "end_time": "2025-02-19T13:13:23.625367Z",
     "start_time": "2025-02-19T13:13:23.623904Z"
    }
   },
   "source": "# pip install python-terrier==0.12.1",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T13:13:23.950824Z",
     "start_time": "2025-02-19T13:13:23.667209Z"
    }
   },
   "source": [
    "import pyterrier as pt"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries and query relevance\n",
    "\n",
    "Let's start by loading an existing dataset. We'll pick one from [the list](https://pyterrier.readthedocs.io/en/latest/datasets.html#available-datasets) that has topics (queries) and QRels available, such as `vaswani`:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T13:13:24.019Z",
     "start_time": "2025-02-19T13:13:24.017580Z"
    }
   },
   "source": [
    "dataset = pt.get_dataset(\"vaswani\")\n",
    "index = dataset.get_index(variant=\"terrier_stemmed\")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first have a look at the queries (topics) in this dataset. Note that this dataset only has one set of queries and QRels (you can see this in the table). If a dataset has multiple sets, you'll need to specify one, for example: `dataset.get_topics(\"test\")`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T13:13:24.473964Z",
     "start_time": "2025-02-19T13:13:24.058967Z"
    }
   },
   "source": [
    "dataset.get_topics()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vaswani topics to /home/jim/.pyterrier/corpora/vaswani/query-text.trec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "query-text.trec: 10.7kiB [00:00, 35.6MiB/s]                  \n",
      "Java started (triggered by _read_topics_trec) and loaded: pyterrier.java, pyterrier.terrier.java [version=5.11 (build: craig.macdonald 2025-01-13 21:29), helper_version=0.0.8]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   qid                                              query\n",
       "0    1  measurement of dielectric constant of liquids ...\n",
       "1    2  mathematical analysis and design details of wa...\n",
       "2    3  use of digital computers in the design of band...\n",
       "3    4    systems of data coding for information transfer\n",
       "4    5  use of programs in engineering testing of comp...\n",
       "..  ..                                                ...\n",
       "88  89  tunnel diode construction and its electrical c...\n",
       "89  90  electronic density of states at the surface of...\n",
       "90  91  resistivity of metallic thin films related to ...\n",
       "91  92  the phenomenon of radiation caused by charged ...\n",
       "92  93  high frequency oscillators using transistors t...\n",
       "\n",
       "[93 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>measurement of dielectric constant of liquids ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>mathematical analysis and design details of wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>use of digital computers in the design of band...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>systems of data coding for information transfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>use of programs in engineering testing of comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>89</td>\n",
       "      <td>tunnel diode construction and its electrical c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>90</td>\n",
       "      <td>electronic density of states at the surface of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>91</td>\n",
       "      <td>resistivity of metallic thin films related to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>92</td>\n",
       "      <td>the phenomenon of radiation caused by charged ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>93</td>\n",
       "      <td>high frequency oscillators using transistors t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Along with the set of queries, we can inspect the corresponding relevance data (QRels). These are tuples of (query, document, label). Note that labels can be either binary (`0` or `1`) or graded (for example, `0` to `3`, where a higher number encodes higher relevance). Tuples where the label is `0` (i.e., no relevance) are often omitted from the QRels.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T13:13:55.734022Z",
     "start_time": "2025-02-19T13:13:55.535178Z"
    }
   },
   "source": [
    "dataset.get_qrels()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading vaswani qrels to /home/jim/.pyterrier/corpora/vaswani/qrels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qrels: 24.3kiB [00:00, 58.0MiB/s]                  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     qid  docno  label\n",
       "0      1   1239      1\n",
       "1      1   1502      1\n",
       "2      1   4462      1\n",
       "3      1   4569      1\n",
       "4      1   5472      1\n",
       "...   ..    ...    ...\n",
       "2078  93   9875      1\n",
       "2079  93   9956      1\n",
       "2080  93  10497      1\n",
       "2081  93  11191      1\n",
       "2082  93  11318      1\n",
       "\n",
       "[2083 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docno</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1239</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1502</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4569</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5472</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>93</td>\n",
       "      <td>9875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>93</td>\n",
       "      <td>9956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>93</td>\n",
       "      <td>10497</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>93</td>\n",
       "      <td>11191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082</th>\n",
       "      <td>93</td>\n",
       "      <td>11318</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2083 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "Using the QRels and the output of a ranking model (i.e., a _ranking_ or a _run_), we can compute ranking metrics that evaluate the quality of our results. Let's start with a BM25 model:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T13:18:18.135343Z",
     "start_time": "2025-02-19T13:18:18.064933Z"
    }
   },
   "source": [
    "bm25 = pt.terrier.Retriever(index, wmodel=\"BM25\")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An _experiment_ in PyTerrier automates the retrieval/ranking and evaluation process. This means that you can get a comprehensive evaluation of models or systems on some test set in a single line of code:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T13:18:21.948424Z",
     "start_time": "2025-02-19T13:18:20.664766Z"
    }
   },
   "source": [
    "from pyterrier.measures import RR, nDCG, MAP\n",
    "\n",
    "pt.Experiment(\n",
    "    [bm25],\n",
    "    dataset.get_topics(),\n",
    "    dataset.get_qrels(),\n",
    "    eval_metrics=[RR @ 10, nDCG @ 20, MAP],\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                name     RR@10   nDCG@20        AP\n",
       "0  TerrierRetr(BM25)  0.719875  0.415377  0.296517"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>RR@10</th>\n",
       "      <th>nDCG@20</th>\n",
       "      <th>AP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TerrierRetr(BM25)</td>\n",
       "      <td>0.719875</td>\n",
       "      <td>0.415377</td>\n",
       "      <td>0.296517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have evaluted our BM25 retriever on the dataset we loaded earlier. We used three of the most common IR metrics, but [PyTerrier supports a very large number of additional metrics](https://pyterrier.readthedocs.io/en/latest/experiments.html#evaluation-measures-objects) through its integration of the [ir-measures](https://github.com/terrierteam/ir_measures) library.\n",
    "\n",
    "**Important**: Usually, a value of `0` indicates _no relevance_, while a value greater than `0` indicates _relevance_. However, this is not always the case; a popular example is the TREC Deep Learning passage ranking task, where [only values greater than `1` indicate relevance](https://trec.nist.gov/data/deep2020.html). In those cases, the threshold can by adjusted by constructing the metric as, for example, `RR(rel=2)`.\n",
    "\n",
    "Note that we used the `@` operator to limit the retrieval depth (number of documents per query) for specific metrics. Furthermore, since both queries (topics) and QRels are simply packaged in a `pandas.DataFrame`, you can easily provide your own data, as long as it is in the right format.\n",
    "\n",
    "### Performance comparisons\n",
    "\n",
    "Experiments let you easily compare multiple ranking approaches. Let's load another ranker, which uses standard TF-IDF, to see how much BM25 improves over it:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T13:28:12.564181Z",
     "start_time": "2025-02-19T13:28:12.556160Z"
    }
   },
   "source": [
    "tf_idf = pt.terrier.Retriever(index, wmodel=\"TF_IDF\")"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run an experiment that evaluates both models on the same data. For better readability, we assign custom names to both approaches.\n",
    "\n",
    "Comparing the approaches in the same experiment allows us to automatically have _statistical significance testing_ performed. By setting `baseline=0`, we tell the function to compute the $p$-values with respect to the first approach (TF-IDF). Furthermore, [PyTerrier supports a number of correction methods](https://pyterrier.readthedocs.io/en/latest/experiments.html#significance-testing); here, we apply Bonferroni correction:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T13:30:09.553452Z",
     "start_time": "2025-02-19T13:30:07.745563Z"
    }
   },
   "source": [
    "pt.Experiment(\n",
    "    [tf_idf, bm25],\n",
    "    dataset.get_topics(),\n",
    "    dataset.get_qrels(),\n",
    "    names=[\"TF-IDF\", \"BM25\"],\n",
    "    eval_metrics=[RR @ 10, nDCG @ 20, MAP],\n",
    "    baseline=0,\n",
    "    correction=\"bonferroni\",\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     name        AP   nDCG@20     RR@10  AP +  AP -  AP p-value  AP reject  \\\n",
       "0  TF-IDF  0.290905  0.410850  0.694666   NaN   NaN         NaN      False   \n",
       "1    BM25  0.296517  0.415377  0.719875  46.0  45.0    0.237317      False   \n",
       "\n",
       "   AP p-value corrected  nDCG@20 +  nDCG@20 -  nDCG@20 p-value  \\\n",
       "0                   NaN        NaN        NaN              NaN   \n",
       "1              0.237317       31.0       34.0         0.309461   \n",
       "\n",
       "   nDCG@20 reject  nDCG@20 p-value corrected  RR@10 +  RR@10 -  RR@10 p-value  \\\n",
       "0           False                        NaN      NaN      NaN            NaN   \n",
       "1           False                   0.309461      9.0      2.0       0.034943   \n",
       "\n",
       "   RR@10 reject  RR@10 p-value corrected  \n",
       "0         False                      NaN  \n",
       "1          True                 0.034943  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>AP</th>\n",
       "      <th>nDCG@20</th>\n",
       "      <th>RR@10</th>\n",
       "      <th>AP +</th>\n",
       "      <th>AP -</th>\n",
       "      <th>AP p-value</th>\n",
       "      <th>AP reject</th>\n",
       "      <th>AP p-value corrected</th>\n",
       "      <th>nDCG@20 +</th>\n",
       "      <th>nDCG@20 -</th>\n",
       "      <th>nDCG@20 p-value</th>\n",
       "      <th>nDCG@20 reject</th>\n",
       "      <th>nDCG@20 p-value corrected</th>\n",
       "      <th>RR@10 +</th>\n",
       "      <th>RR@10 -</th>\n",
       "      <th>RR@10 p-value</th>\n",
       "      <th>RR@10 reject</th>\n",
       "      <th>RR@10 p-value corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.290905</td>\n",
       "      <td>0.410850</td>\n",
       "      <td>0.694666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.296517</td>\n",
       "      <td>0.415377</td>\n",
       "      <td>0.719875</td>\n",
       "      <td>46.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.237317</td>\n",
       "      <td>False</td>\n",
       "      <td>0.237317</td>\n",
       "      <td>31.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.309461</td>\n",
       "      <td>False</td>\n",
       "      <td>0.309461</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.034943</td>\n",
       "      <td>True</td>\n",
       "      <td>0.034943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving results\n",
    "\n",
    "Experiments allow for saving the obtained results (runs) in the common TREC format:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T13:30:59.600754Z",
     "start_time": "2025-02-19T13:30:57.212928Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "\n",
    "results_dir = Path.cwd() / \"04_data\" / \"results\"\n",
    "results_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "pt.Experiment(\n",
    "    [tf_idf, bm25],\n",
    "    dataset.get_topics(),\n",
    "    dataset.get_qrels(),\n",
    "    names=[\"TF-IDF\", \"BM25\"],\n",
    "    eval_metrics=[RR @ 10, nDCG @ 20, MAP],\n",
    "    save_dir=str(results_dir),\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     name     RR@10   nDCG@20        AP\n",
       "0  TF-IDF  0.694666  0.410850  0.290905\n",
       "1    BM25  0.719875  0.415377  0.296517"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>RR@10</th>\n",
       "      <th>nDCG@20</th>\n",
       "      <th>AP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.694666</td>\n",
       "      <td>0.410850</td>\n",
       "      <td>0.290905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BM25</td>\n",
       "      <td>0.719875</td>\n",
       "      <td>0.415377</td>\n",
       "      <td>0.296517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is useful when results need to be shared or processed futher. In addition, PyTerrier will re-use saved results rather than re-computing them. This behavior can be disabled by setting `save_mode=\"overwrite\"`.\n",
    "\n",
    "## Further reading\n",
    "\n",
    "Check out the [section on experiments](https://pyterrier.readthedocs.io/en/latest/experiments.html) in the documentation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
